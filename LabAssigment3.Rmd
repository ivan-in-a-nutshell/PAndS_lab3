---
title: "LabAssigment3"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

-   Problem 1 - Yarema

-   Problem 2 - Olha

-   Problem 3 - Ivan

# Lab 3: Parameter estimation and Unbiasedness of Estimators

## Problem 1
## Problem understanding:
We need to verify that four different methods for constructing confidence intervals for the exponential distribution parameter Î¸ = 1/Î» achieve the nominal coverage probability (1-Î±) and compare their precision.
```{r}
id <- 6
set.seed(id)
theta <- id/10  
lambda <- 1/theta
alpha_values <- c(0.1, 0.05, 0.01)
sample_sizes <- c(10, 30, 100)
m <- 1000  
```
## Comment for 1 block:
Sets initial parameters. theta = team_id/10, alpha levels for 90%, 95%, 99% CI, sample sizes to test, and m=1000 simulations for accuracy

```{r}
calculate_ci <- function(sample, alpha, method) {
  n <- length(sample)
  x_bar <- mean(sample)
  
  if (method == 1) {
    lower <- (2 * n * x_bar) / qchisq(1 - alpha/2, df = 2*n)
    upper <- (2 * n * x_bar) / qchisq(alpha/2, df = 2*n)
  } else if (method == 2) {
    z <- qnorm(1 - alpha/2)
    lower <- x_bar - z * theta / sqrt(n)
    upper <- x_bar + z * theta / sqrt(n)
  } else if (method == 3) {
    z <- qnorm(1 - alpha/2)
    a <- 1 + (z^2)/n
    b <- -2 * x_bar
    c <- x_bar^2
    discriminant <- b^2 - 4*a*c
    
    if (discriminant < 0) {
      return(c(NA, NA, NA)) 
    }
    
    lower <- (-b - sqrt(discriminant)) / (2*a)
    upper <- (-b + sqrt(discriminant)) / (2*a)
    
    if (lower < 0 || upper < lower) {
      return(c(NA, NA, NA))
    }
  } else if (method == 4) {
    t_val <- qt(1 - alpha/2, df = n-1)
    se <- sd(sample) / sqrt(n)
    lower <- x_bar - t_val * se
    upper <- x_bar + t_val * se
  }
  
  return(c(lower, upper, upper - lower))
}
```
## Comment for block 2:
Implements all 4 CI methods. Method 1 uses exact Ï‡Â² distribution. Method 2 uses normal approximation with theoretical variance. Method 3 solves inequality to eliminate unknown parameter. Method 4 uses t-distribution with sample standard error
```{r}
results <- list()

for (alpha in alpha_values) {
  for (n in sample_sizes) {
    coverage <- numeric(4)
    avg_length <- numeric(4)
    
    for (method in 1:4) {
      coverage_count <- 0
      total_length <- 0
      valid_simulations <- 0
      
      for (i in 1:m) {
        sample <- rexp(n, rate = lambda)
        ci <- calculate_ci(sample, alpha, method)
        
        if (!any(is.na(ci))) {
          if (ci[1] <= theta && theta <= ci[2]) {
            coverage_count <- coverage_count + 1
          }
          total_length <- total_length + ci[3]
          valid_simulations <- valid_simulations + 1
        }
      }
      
      if (valid_simulations > 0) {
        coverage[method] <- coverage_count / valid_simulations
        avg_length[method] <- total_length / valid_simulations
      } else {
        coverage[method] <- NA
        avg_length[method] <- NA
      }
    }
    
    results[[paste("alpha", alpha, "n", n)]] <- list(
      coverage = coverage,
      avg_length = avg_length
    )
  }
}
```
## Comment for block 3:
Runs simulation for each alpha and sample size. For each method, generates m samples, computes CIs, tracks coverage rate and average interval length
```{r}
cat("SIMULATION RESULTS\n")
cat("=================\n\n")

for (alpha in alpha_values) {
  for (n in sample_sizes) {
    key <- paste("alpha", alpha, "n", n)
    cat("Alpha =", alpha, ", n =", n, ", Theoretical Coverage =", 1-alpha, "\n")
    cat("Method | Coverage | Avg Length\n")
    for (method in 1:4) {
      cat(sprintf("%6d | %8.3f | %10.3f\n", 
                  method, 
                  results[[key]]$coverage[method],
                  results[[key]]$avg_length[method]))
    }
    cat("\n")
  }
}
```
## Comment for block 4:
Displays results in clean table format showing empirical coverage probability and average interval length for each method
```{r}
library(ggplot2)

plot_data <- data.frame()
for (alpha in alpha_values) {
  for (n in sample_sizes) {
    key <- paste("alpha", alpha, "n", n)
    for (method in 1:4) {
      plot_data <- rbind(plot_data, 
        data.frame(alpha = factor(alpha), n = n, method = factor(method), 
                  coverage = results[[key]]$coverage[method],
                  length = results[[key]]$avg_length[method]))
    }
  }
}

ggplot(plot_data, aes(x = factor(n), y = coverage, fill = method)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~alpha) +
  geom_hline(aes(yintercept = 1-as.numeric(as.character(alpha))), 
             linetype = "dashed", color = "red") +
  labs(title = "Coverage Probabilities", x = "Sample Size", y = "Coverage")

ggplot(plot_data, aes(x = factor(n), y = length, fill = method)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~alpha) +
  labs(title = "Average CI Lengths", x = "Sample Size", y = "Length")
```
## Comment for block 5:
Creates visualizations comparing coverage probabilities (with theoretical reference line) and interval lengths across methods and sample sizes.

## Explanation of all 4 methods:
- Method 1: Uses the exact distribution property that for exponential distribution, 2Î»nXÌ„ âˆ¼ Ï‡Â²(2n)

- Method 2: Applies Central Limit Theorem - for large n, âˆšn(XÌ„ - Î¸)/Î¸ â‰ˆ N(0,1)

- Method 3: Solves the inequality to eliminate the unknown parameter Î¸

- Method 4: Uses t-distribution which is appropriate when population variance is unknown

## Conclusion:
Based on the simulation results:

Coverage accuracy: Method 1 (exact) consistently achieves coverage closest to the theoretical level across all sample sizes. Method 4 performs reasonably well, especially for larger samples.

Precision: Methods 2 and 3 often produce shorter intervals but may undercover for small samples.

Recommendation: Method 4 (t-distribution) is recommended as the best overall method because:

- It provides good coverage accuracy

- It doesn't require knowing the true variance

- It works well for various sample sizes

- It's widely applicable in practice

The results are reliable due to the large number of simulations (m=1000), and they agree with common sense expectations that exact methods should perform best, but practical methods like t-distribution offer a good balance between accuracy and applicability.

## Problem 2
In this task we study four different methods for constructing confidence intervals for the parameter ðœƒ of a Poisson distribution.

Our goals are:
To verify whether the confidence intervals of nominal level 1 âˆ’ Î± contain the true parameter ðœƒ approximately 100(1 âˆ’ Î±)% of the time.
To compare the precision of these intervals (mean and maximum length).
To identify which method works best for Poisson data.
To study the effect of sample size n by considering n = 10, 30, 100; M = 10000 repetitions.

To construct and evaluate the confidence intervals, we used the following sample statistics extracted from simulated Poisson data: sample mean, sample variance, confident intervals lengths and coverage probability.
```{r}
install.packages("rmarkdown")
set.seed(6)
theta <- 0.6
alpha_vec <- c(0.1, 0.05, 0.01)

simulate_once <- function(n, M, theta, alpha_vec){
  # Generate values with Poisson(theta) distribution
  x <- matrix(rpois(n*M, lambda = theta), nrow = n)
  sample_mean <- colMeans(x)
  sample_sd   <- apply(x, 2, sd)
  
  for (alpha in alpha_vec){
    z <- qnorm(1 - alpha/2)
    tcrit <- qt(1 - alpha/2, df = n - 1)
    
    #2: normal CI with known variance Î¸
    se_known <- sqrt(theta / n)
    lower2 <- sample_mean - z * se_known
    upper2 <- sample_mean + z * se_known
    cover2 <- mean(theta >= lower2 & theta <= upper2)
    len2   <- mean(upper2 - lower2)   # Ð´Ð¾Ð²Ð¶Ð¸Ð½Ð° Ñ‚ÑƒÑ‚ Ð¾Ð´Ð½Ð°ÐºÐ¾Ð²Ð°, Ð°Ð»Ðµ Ð±ÐµÑ€ÐµÐ¼Ð¾ mean
    
    #3: solved quadratic inequality
    # Î¸1,2 = (2n xÌ„ + z^2 Â± sqrt(4 n z^2 xÌ„ + z^4)) / (2n)
    disc <- sqrt(4 * n * z^2 * sample_mean + z^4)
    lower3 <- (2 * n * sample_mean + z^2 - disc) / (2 * n)
    upper3 <- (2 * n * sample_mean + z^2 + disc) / (2 * n)
    
    cover3 <- mean(theta >= lower3 & theta <= upper3)
    len3_mean <- mean(upper3 - lower3)
    len3_max  <- max(upper3 - lower3)
    
    #4: t-interval with sample sd
    se_hat <- sample_sd / sqrt(n)
    lower4 <- sample_mean - tcrit * se_hat
    upper4 <- sample_mean + tcrit * se_hat
    
    cover4 <- mean(theta >= lower4 & theta <= upper4)
    len4_mean <- mean(upper4 - lower4)
    len4_max  <- max(upper4 - lower4)
    
    cat("n =", n, ", M =", M, ", alpha =", alpha, "\n")
    cat("  Method (2) known var:   coverage =", cover2,
        ", mean length =", len2, "\n")
    cat("  Method (3) quadratic:   coverage =", cover3,
        ", mean length =", len3_mean,
        ", max length =", len3_max, "\n")
    cat("  Method (4) t-interval:  coverage =", cover4,
        ", mean length =", len4_mean,
        ", max length =", len4_max, "\n\n")
  }
}

n <- 30
M <- 10000
theta <- 0.6

x <- rpois(M, theta)
hist(x, breaks = 20, col = "skyblue",
     main = "Distribution of single Poisson observations",
     xlab = "X")

means <- replicate(M, mean(rpois(n, theta)))
hist(means, breaks = 30, col = "lightgreen",
     main = "Distribution of sample mean",
     xlab = "Sample mean")

simulate_once(n = 10,  M = 10000, theta = theta, alpha_vec = alpha_vec)
simulate_once(n = 30,  M = 10000, theta = theta, alpha_vec = alpha_vec)
simulate_once(n = 100, M = 10000, theta = theta, alpha_vec = alpha_vec)
```
Before running the simulation, we visualized individual Poisson observations and distribution of the sample mean. This illustrates that although individual Poisson values are skewed, the sample mean becomes close to normal as n increases.

#### Results for n = 10

Method 2: coverage slightly below the nominal level
Method 3: similar but slightly more variable
Method 4: significant undercoverage (often around 0.85 instead of 0.95)
For small samples, the Poisson distribution is highly skewed andnormal-based methods fail.
The t-interval performs worst because the sample variance fluctuates strongly.

#### Results for n = 30

All methods have coverage close to the theoretical level
Intervals become shorter and more stable
Method 4 (t-interval) now works reasonably well
CLT becomes accurate; normal approximations are reliable;
differences between the methods decrease.

#### Results for n = 100

Coverage extremely close to 1 âˆ’ Î±
All interval lengths almost identical
Maximum lengths no longer problematic
For large n, all approximations are excellent and there is no practical difference between the methods.

## Problem 3

```{r}
set.seed(42)
mu <- 10
sigma_squared <- 4
sigma <- sqrt(sigma_squared)

cat("Population Mean (mu):", mu, "\n")
cat("Population Variance (sigma_squared):", sigma_squared, "\n")

for (n in c(10, 50, 100, 1000)) {
  cat("---------------------------------\n")
  cat("----- Simulation for n =", n, "-----\n")
  dataset <- rnorm(n, mean = mu, sd = sigma)
  sample_mean <- mean(dataset)
  
  var_n <- sum((dataset - sample_mean) ^ 2) / n
  var_n_minus1 <- var_n * n / (n - 1)
  cat("Biased sample variance:", var_n, "\n")
  cat("Bias:", -sigma_squared / n, "\n")
  cat("Unbiased sample variance:", var_n_minus1, "\n")
  cat("Bias:", 0, "\n")
}
```

As $$n$$ increases the bias of the biased estimator $$\sigma_n^2$$ gets closer to zero. As we can see the bias is always negative, meaning it always slightly underestimates the true variance.

Let's analize $$\sum(X_i - \bar{X})^2$$

$$
\sum_{i=1}^{n}(X_i - \bar{X})^2 = \sum_{i=1}^{n}((X_i - \mu) - (\bar{X} - \mu))^2 \\
\Rightarrow \sum_{i=1}^{n}(X_i - \mu)^2 - 2 (\bar{X} - \mu) \sum_{i=1}^{n}(X_i - \mu) + \sum_{i=1}^{n} (\bar{X} - \mu)^2 \\
\Rightarrow \sum_{i=1}^{n}(X_i - \mu)^2 -2n(\bar{X} - \mu)^2 + n(\bar{X} - \mu) ^ 2 \\
\Rightarrow \sum_{i=1}^{n}(X_i - \mu)^2 -n(\bar{X} - \mu)^2
$$

Now take expectation from both sides

$$
E \left [ \sum_{i=1}^{n}(X_i - \bar{X})^2 \right] = E \left [\sum_{i=1}^{n}(X_i - \mu)^2 -n(\bar{X} - \mu)^2 \right ] \\
= \sum_{i=1}^{n}\sigma^2 - n \frac{\sigma^2}{n} = n\sigma^2 - \sigma^2 = (n - 1)\sigma^2
$$

Now for $$E[\sigma_{n-1}^2]$$

$$
E[\sigma_{n-1}^2] = E \left [\frac{1}{n-1} \sum_{i=1}^{n}(X_i - \bar{X})^2 \right] = \frac{1}{n-1}(n-1)\sigma^2=\sigma^2
$$

Now for $$E[\sigma_{n}^2]$$

$$
E[\sigma_{n}^2] = E \left [\frac{1}{n} \sum_{i=1}^{n}(X_i - \bar{X})^2 \right] = \frac{1}{n}(n-1)\sigma^2 = \frac{n-1}{n}\sigma^2 = \sigma^2 - \frac{\sigma^2}{n}
$$

Since $$E[\sigma_{n-1}^2] = \sigma^2$$, therefore $$\sigma_{n-1}^2$$ is an unbiased estimator

Since $$E[\sigma_{n}^2] = \sigma^2 - \frac{\sigma^2}{n} $$, therefore $$\sigma_{n}^2$$ is a biased estimator

Comments on work:

From theoretical calculations we saw, that $$\sigma_{n-1}^2$$ is an unbiased estimator.

In practice when having large enough $$n$$ the difference between the estimators is negligible.
